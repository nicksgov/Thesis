{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import warnings\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from tsmoothie.smoother import ConvolutionSmoother\n",
    "from tsmoothie.bootstrap import BootstrappingWrapper\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.mixture import BayesianGaussianMixture as BGMM\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import AgglomerativeClustering as hier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import rcParams\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# sns.set()\n",
    "\n",
    "class Bus:\n",
    "\n",
    "    def __init__(self, real_d=1, react_d=1, days=365):\n",
    "        self.days = days\n",
    "        self.real_d = real_d\n",
    "        self.react_d = react_d\n",
    "        if ((self.real_d != 1) & (self.react_d != 1)):\n",
    "            self.real = self.read(self.real_d, self.days)\n",
    "            self.react = self.read(self.react_d, self.days)\n",
    "\n",
    "    # thn kaloume pio panw kai ftiaxnei thn class\n",
    "    def read(self, directory, days):\n",
    "        dateparse = lambda j: dt.datetime.strptime(str(j), \"%Y%m%d%H%M\")\n",
    "\n",
    "        cells = ['Date', 'Value']\n",
    "        X = pd.read_excel(directory, usecols=[3, 4], nrows=96 * days, header=None, names=cells,\n",
    "                          index_col='Date', parse_dates=True, date_parser=dateparse)\n",
    "        return X\n",
    "\n",
    "    # dinei stats gia real kai react\n",
    "    def stats(self):\n",
    "        mean = self.real['Value'].mean()\n",
    "        var = self.real['Value'].var()\n",
    "        mean_r = self.react['Value'].mean()\n",
    "        var_r = self.react['Value'].var()\n",
    "        print(\"mean real = {:.2f}, \\nvar real = {:.2f}, \\nmean react = {:.2f}, \\nvar react = {:.2f}\".format(mean, var,\n",
    "                                                                                                            mean_r,\n",
    "                                                                                                            var_r))\n",
    "\n",
    "    # epistrefei ena mhna san DFr, dexetai power = 'real','react','all' kai month\n",
    "    def month(self, year=2018, month=1, power='real'):\n",
    "        start = dt.datetime(year, month, 1)\n",
    "        if (month != 12):\n",
    "            end = dt.datetime(year, month + 1, 1)\n",
    "        else:\n",
    "            end = dt.datetime(year + 1, 1, 1)\n",
    "\n",
    "        if power == 'real':\n",
    "            return self.real.iloc[(self.real.index >= start) & (self.real.index < end)]\n",
    "        elif power == 'react':\n",
    "            return self.react.iloc[(self.react.index >= start) & (self.react.index < end)]\n",
    "        elif power == 'all':\n",
    "            a = self.real.iloc[(self.real.index >= start) & (self.real.index < end)]\n",
    "            b = self.react.iloc[(self.react.index >= start) & (self.react.index < end)]\n",
    "            \n",
    "            return a, b\n",
    "    def season(self, year=2018, season ='winter', power='real'):\n",
    "        \n",
    "        if season == 'winter':\n",
    "            months =[12,1,2]\n",
    "        elif season == 'spring':\n",
    "            months = [3, 4, 5]\n",
    "        elif season == 'summer':\n",
    "            months = [6, 7, 8]\n",
    "        elif season == 'fall':\n",
    "            months = [9, 10, 11]\n",
    "        season = pd.DataFrame()\n",
    "        for month in months:\n",
    "            season = season.append(self.month(month=month, power=power))\n",
    "        return season, months\n",
    "    \n",
    "\n",
    "\n",
    "# δεχεται το Χ['Value'] και επιστρεφει weekdays,weekends\n",
    "def workdays(data):\n",
    "    data.name = 'Value'\n",
    "    data = pd.DataFrame(data)\n",
    "    func = lambda x: x.index.weekday + 1\n",
    "    data['Weekday'] = data.apply(func)\n",
    "\n",
    "    Weekdays = data['Value'].loc[data['Weekday'] <= 5]\n",
    "    Weekends = data['Value'].loc[data['Weekday'] > 5]\n",
    "\n",
    "    return Weekdays, Weekends\n",
    "\n",
    "\n",
    "     \n",
    "def choose(howmany, fromwhere, positions):\n",
    "    import random \n",
    "    chose_from = [fromwhere[i] for i in positions]\n",
    "    chosen = random.sample(chose_from, k=howmany)\n",
    "    return chosen\n",
    "\n",
    "def workdayspermonth(month=1,year=2018):\n",
    "    start = dt.date(year, month, 1)\n",
    "    if (month != 12):\n",
    "        end = dt.date(year, month + 1, 1)\n",
    "    else:\n",
    "        end = dt.date(year + 1, 1, 1)\n",
    "    wdays = np.busday_count(start, end)\n",
    "    wends = (end-start).days-wdays\n",
    "    return wdays,wends\n",
    "\n",
    "\n",
    "def unique(list1):\n",
    "# initialize a null list\n",
    "    unique_list = []\n",
    "\n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "    return unique_list\n",
    "\n",
    "# Οπτικοποίηση δεδομένων με clustering\n",
    "def visualization(data, days, n_components=10, labels=1, title= 'Generated'):\n",
    "    \n",
    "    Y = np.array(data).reshape(-1,96)\n",
    "    dic = Y[0:days]\n",
    "\n",
    "    compon = n_components\n",
    "    model = GMM(n_components=compon,max_iter=1000, random_state=1)\n",
    "    if labels == 1: labels = [model.fit_predict(dic)]\n",
    "    \n",
    "\n",
    "    axis = np.array\n",
    "    axis = np.arange(96)\n",
    "    cols = 6\n",
    "    rows = int(compon//6 + 1) if (compon%6 != 0)  else int(compon//6)\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=cols, nrows=rows, sharey=True, figsize=(30,12));\n",
    "    for i, j in enumerate(dic):\n",
    "        sns.lineplot(x=axis, y=j, ax=axs[labels[0][i]//cols][labels[0][i]%cols])\n",
    "    \n",
    "    flattened_axs = np.ravel(axs)\n",
    "    # Set titles for each subplot in the flattened array\n",
    "    for i, ax in enumerate(flattened_axs):\n",
    "        ax.set_title(f'Cluster {i+1}')\n",
    "    #title of figure\n",
    "    fig.suptitle(title, fontsize=30)\n",
    "\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def find_occurrence(lista, value, number_of_occurrence):\n",
    "    count = 0\n",
    "    for index, item in enumerate(lista):\n",
    "        if item == value:\n",
    "            count += 1\n",
    "            if count == number_of_occurrence:\n",
    "                return index\n",
    "    return -1  # Return -1 if the occurrence is not found\n",
    "\n",
    "def without_extreme_outliers (data, labels, threshold = 3.0):\n",
    "    from scipy.stats import zscore\n",
    "    data = np.array(data).reshape(-1,96)\n",
    "    \n",
    "    unique_labels = np.unique(labels)\n",
    "    outlier_points_per_label = {}  # Dictionary to store outlier positions for each label\n",
    "    zscore_threshold = threshold  # Set the z-score threshold for identifying outliers\n",
    "    mean_per_labels_column = [] #size (labels,96)\n",
    "\n",
    "    for label in unique_labels:\n",
    "        # Step 1: Create a subset of Y for the current label\n",
    "        part_data = data[labels[0] == label]\n",
    "\n",
    "        # Step 2: Calculate the mean of each column in part_Y\n",
    "        column_means = np.mean(part_data, axis=0)\n",
    "        mean_per_labels_column.append(column_means)\n",
    "\n",
    "        # Step 3: Calculate the z-scores for each data point in part_Y\n",
    "        zscores = zscore(part_data, axis=0)\n",
    "\n",
    "        # Step 4: Find the indices of outliers based on the z-score threshold\n",
    "        outlier_indices = np.where(np.abs(zscores) > zscore_threshold)\n",
    "\n",
    "        # Step 5: Save the positions of time series with outliers for the current label\n",
    "        outlier_points_per_label[label] = outlier_indices\n",
    "        \n",
    "        # Antikatastash extreme outliers me meso oro ekeinhs ths sthlhw ana column\n",
    "        for key in outlier_points_per_label:\n",
    "            for count, row in enumerate(outlier_points_per_label[key][0]):\n",
    "                data[find_occurrence(labels[0],key,row+1)][outlier_points_per_label[key][1][count]] = mean_per_labels_column[key][[outlier_points_per_label[key][1][count]]][0]\n",
    "\n",
    "    return data\n",
    "\n",
    "#find transition matrix for markov chain if you have a sequence\n",
    "def trans_matrix (sequence):\n",
    "    seq = sequence\n",
    "    return pd.crosstab(pd.Series(seq[:-1],name='State'), pd.Series(seq[1:],name='Next state'), normalize = 'index')\n",
    "\n",
    "#simulate a sequence if you have a transition matrix\n",
    "def simul_markov(tran_matr, state_zero=0, lenght = 10):\n",
    "    sim = []\n",
    "    #state zero\n",
    "    state_zero = state_zero\n",
    "    #next state\n",
    "    n_state = np.random.choice(tran_matr.iloc[state_zero].index, p = tran_matr.iloc[state_zero])\n",
    "\n",
    "    while len(sim) < lenght:\n",
    "        sim.append(n_state)\n",
    "        n_state = np.random.choice(tran_matr.iloc[tran_matr.index.get_loc(n_state)].index, p = tran_matr.iloc[tran_matr.index.get_loc(n_state)])\n",
    "    return sim\n",
    "\n",
    "# pairnei data, way (yearly, monthly), month kai epistrefei T,S,RES, REAL\n",
    "def decompose_bootstrap(data, year=2018, month=1, period=96):\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(14, 14))\n",
    "    fig.tight_layout()\n",
    "   \n",
    "    # vriskw start kai end\n",
    "    start = dt.datetime(year, month, 1)\n",
    "    if (month != 12):\n",
    "        end = dt.datetime(year, month + 1, 1)\n",
    "    else:\n",
    "        end = dt.datetime(year + 1, 1, 1)\n",
    "\n",
    "    series = data['Value'].iloc[(data.index >= start) & (data.index < end)]\n",
    "    results = seasonal_decompose(series, model=\"aditive\", extrapolate_trend=1, period=period)\n",
    "    trend_estimate = results.trend\n",
    "    periodic_estimate = results.seasonal\n",
    "    residual = results.resid\n",
    "\n",
    "    axes[0].plot(series, label='Original time series', color='blue')\n",
    "    axes[1].plot(trend_estimate, label='Trend of time series', color='blue')\n",
    "    axes[2].plot(periodic_estimate, label='Seasonality of time series', color='blue')\n",
    "    axes[3].plot(residual, label='Decomposition residuals of time series', color='blue')\n",
    "\n",
    "    for i in axes:\n",
    "        i.legend(loc='best')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    return trend_estimate, periodic_estimate, residual, series\n",
    "\n",
    "def decompose_bootstrap_year(data, year=2018, period=96):\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(14, 14))\n",
    "    fig.tight_layout()\n",
    "   \n",
    "    # vriskw start kai end\n",
    "    start = dt.datetime(2018, 1, 1)\n",
    "    end = dt.datetime(2019, 1, 1)\n",
    "\n",
    "    series = data['Value'].iloc[(data.index >= start) & (data.index < end)]\n",
    "    results = seasonal_decompose(series, model=\"aditive\", extrapolate_trend=1, period=period)\n",
    "    trend_estimate = results.trend\n",
    "    periodic_estimate = results.seasonal\n",
    "    residual = results.resid\n",
    "\n",
    "    axes[0].plot(series, label='Original time series', color='blue')\n",
    "    axes[1].plot(trend_estimate, label='Trend of time series', color='blue')\n",
    "    axes[2].plot(periodic_estimate, label='Seasonality of time series', color='blue')\n",
    "    axes[3].plot(residual, label='Decomposition residuals of time series', color='blue')\n",
    "\n",
    "    for i in axes:\n",
    "        i.legend(loc='best')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return trend_estimate, periodic_estimate, residual\n",
    "\n",
    "\n",
    "# pairnei residuals kai dinei resampled\n",
    "def bootstrap_res(residual):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.tight_layout()\n",
    "    data = residual\n",
    "    axis = np.arange(0, len(data))\n",
    "    vlines = np.arange(0, len(data), 96)\n",
    "\n",
    "    # epilogh smoother\n",
    "    smoother1 = ConvolutionSmoother(window_len=len(data), window_type='ones')\n",
    "\n",
    "    # epistrofi smoothed data gia plot\n",
    "    a1 = smoother1.smooth(data)\n",
    "\n",
    "    # paragwgh samples kai eyresi mean\n",
    "    bts = BootstrappingWrapper(a1, bootstrap_type='nbb', block_length=96)\n",
    "    bts_samples = bts.sample(data, n_samples=1)\n",
    "    mean = bts_samples.mean(axis=0)\n",
    "\n",
    "    plt.subplot(211)\n",
    "    # smoothed\n",
    "    sns.lineplot(x=axis, y=a1.smooth_data[0], linewidth=2, color='green')\n",
    "    # real\n",
    "    sns.lineplot(x=axis, y=data, linewidth=1)\n",
    "    plt.vlines(x=vlines, ymin=min(data), ymax=max(data), colors='red')\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.vlines(x=vlines, ymin=min(data), ymax=max(data), colors='red')\n",
    "    # samples\n",
    "    plt.plot(axis, bts_samples.T, alpha=2, c='orange')\n",
    "\n",
    "    # mean\n",
    "    sns.lineplot(x=axis, y=mean, linewidth=1)\n",
    "    plt.close()\n",
    "\n",
    "    return mean.tolist()\n",
    "\n",
    "def concatinate(WD, WE, month=1):\n",
    "    \n",
    "    start = dt.datetime(2018, month, 1)\n",
    "    if (month != 12):\n",
    "        end = dt.datetime(2018, month + 1, 1)\n",
    "    else:\n",
    "        end = dt.datetime(2018 + 1, 1, 1)\n",
    "\n",
    "    days = pd.date_range(start=start, end=end, freq='1D', closed='left')\n",
    "    we_iter = 0\n",
    "    wd_iter = 0\n",
    "    bs_month = []\n",
    "    for day in days:\n",
    "        if (day.weekday() < 5):\n",
    "            bs_month.extend(WD[wd_iter:(wd_iter + 96)])\n",
    "            wd_iter += 96\n",
    "        else:\n",
    "            bs_month.extend(WE[we_iter:(we_iter + 96)])\n",
    "            we_iter += 96\n",
    "\n",
    "    index = pd.date_range(start=start, end=end, freq='15min', closed='left')\n",
    "    bs_month = pd.Series(bs_month, index=index)\n",
    "    return bs_month\n",
    "\n",
    "def concatinate_season(dictmonths, months):\n",
    "    import collections\n",
    "    Months = collections.OrderedDict(sorted(dictmonths.items()))\n",
    "    bs_month = []\n",
    "    for month in months:\n",
    "        start = dt.datetime(2018, month, 1)\n",
    "        if (month != 12):\n",
    "            end = dt.datetime(2018, month + 1, 1)\n",
    "        else:\n",
    "            end = dt.datetime(2018 + 1, 1, 1)\n",
    "        days = pd.date_range(start=start, end=end, freq='1D', closed='left')\n",
    "        we_iter = 0\n",
    "        wd_iter = 0\n",
    "        for day in days:\n",
    "            if (day.weekday() < 5):\n",
    "                bs_month.extend(Months[month][0][wd_iter])\n",
    "                wd_iter += 1\n",
    "            else:\n",
    "                bs_month.extend(Months[month][1][we_iter])\n",
    "                we_iter += 1\n",
    "\n",
    "    bs_month = np.array(bs_month)\n",
    "    bs_month = bs_month.reshape(-1,96)\n",
    "    return bs_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_season_2_1(data, season, dict_months, months):\n",
    "    def unique(list1):\n",
    "    # initialize a null list\n",
    "        unique_list = []\n",
    "\n",
    "        # traverse for all elements\n",
    "        for x in list1:\n",
    "            # check if exists in unique_list or not\n",
    "            if x not in unique_list:\n",
    "                unique_list.append(x)\n",
    "        return unique_list\n",
    "    \n",
    "    data = data\n",
    "    season = season\n",
    "    Months = dict_months\n",
    "    months = months\n",
    "    \n",
    "    # Χωρίζω εργάσιμες και κανονικές\n",
    "    wd,we = workdays(data)\n",
    "    wd.shape, we.shape\n",
    "    wd_np = np.array(wd).reshape(-1,96)\n",
    "    we_np = np.array(we).reshape(-1,96)\n",
    "\n",
    "    # Φιτάρω εργασιμες, κανονικες ξεχωριστα και παράγω 200 δείγματα για το καθένα\n",
    "    modelwd = GMM(n_components=5, random_state=123)\n",
    "    modelwe = GMM(n_components=3, random_state=123)\n",
    "    labelswd = modelwd.fit_predict(wd_np)\n",
    "    labelswe = modelwe.fit_predict(we_np)\n",
    "    xwd, ywd = modelwd.sample(n_samples=500)\n",
    "    xwe, ywe = modelwe.sample(n_samples=500)\n",
    "\n",
    "    # Χωρίζω σε Wds, Wes τοσο τα real οσο και τα generated\n",
    "    uniquewd = unique(labelswd)\n",
    "    uniquewe = unique(labelswe)\n",
    "\n",
    "    dictywd = {}\n",
    "    for unique in uniquewd:\n",
    "        dictywd[unique] = [i for i,j in enumerate(ywd) if j==unique]\n",
    "\n",
    "    dictrwd = {}\n",
    "    for unique in uniquewd:\n",
    "        dictrwd[unique] = [i for i,j in enumerate(labelswd) if j==unique]\n",
    "\n",
    "    dictrwe = {}\n",
    "    for unique in uniquewe:\n",
    "        dictrwe[unique] = [i for i,j in enumerate(labelswe) if j==unique]\n",
    "\n",
    "    dictywe = {}\n",
    "    for unique in uniquewe:\n",
    "        dictywe[unique] = [i for i,j in enumerate(ywe) if j==unique]\n",
    "\n",
    "    \n",
    "    # Κανω δειγματοληψία απο τα generated για το σύνολο των WDs, WEs της εποχής, \n",
    "    #οπότε έχω δύο arrays με τόσα generated όσα οι WEs, WDs της εποχής αντίστοιχα\n",
    "\n",
    "    genwd = np.array(wd_np)\n",
    "    for cluster in uniquewd:\n",
    "        chosen = choose(len(dictrwd[cluster]),xwd,dictywd[cluster])\n",
    "        for i,k in zip(dictrwd[cluster],chosen):\n",
    "            genwd[i] = k.round(2)\n",
    "\n",
    "    genwe = np.array(we_np)\n",
    "    for cluster in uniquewe:\n",
    "        chosen = choose(len(dictrwe[cluster]),xwe,dictywe[cluster])\n",
    "        for i,k in zip(dictrwe[cluster],chosen):\n",
    "            genwe[i] = k.round(2)\n",
    "\n",
    "    sumwd = sumwe = 0\n",
    "    for month in months:\n",
    "        wdays, wends = workdayspermonth(month=month)\n",
    "        Months[month] = (genwd[sumwd:sumwd+wdays],genwe[sumwe:sumwe+wends])\n",
    "        sumwd += wdays\n",
    "        sumwe += wends\n",
    "        \n",
    "    return Months\n",
    "\n",
    "def generate_season_2_2(data, season, dict_months, months):\n",
    "    def unique(list1):\n",
    "    # initialize a null list\n",
    "        unique_list = []\n",
    "\n",
    "        # traverse for all elements\n",
    "        for x in list1:\n",
    "            # check if exists in unique_list or not\n",
    "            if x not in unique_list:\n",
    "                unique_list.append(x)\n",
    "        return unique_list\n",
    "    \n",
    "    data = data\n",
    "    season = season\n",
    "    Months = dict_months\n",
    "    months = months\n",
    "    \n",
    "    # Χωρίζω εργάσιμες και κανονικές\n",
    "    wd,we = workdays(data)\n",
    "    wd.shape, we.shape\n",
    "    wd_np = np.array(wd).reshape(-1,96)\n",
    "    we_np = np.array(we).reshape(-1,96)\n",
    "\n",
    "    # Φιτάρω εργασιμες, κανονικες ξεχωριστα και παράγω 200 δείγματα για το καθένα\n",
    "    modelwd = GMM(n_components=5, random_state=123)\n",
    "    modelwe = GMM(n_components=3, random_state=123)\n",
    "    labelswd = modelwd.fit_predict(wd_np)\n",
    "    labelswe = modelwe.fit_predict(we_np)\n",
    "    xwd, ywd = modelwd.sample(n_samples=800)\n",
    "    xwe, ywe = modelwe.sample(n_samples=800)\n",
    "\n",
    "    # Βρισκω trans Matrix για labels των real δεδομενων\n",
    "    transM_wd = trans_matrix(labelswd)\n",
    "    transM_we = trans_matrix(labelswe)\n",
    "\n",
    "    # Κανω simulate μια λιστα με βαση τον προηγουμενο trans matrix\n",
    "    simul_labels_wd = simul_markov(transM_wd, state_zero=labelswd[0], lenght=len(labelswd))\n",
    "    simul_labels_we = simul_markov(transM_we, state_zero=labelswe[0], lenght=len(labelswe))\n",
    "\n",
    "    uniquewd = unique(simul_labels_wd)\n",
    "    uniquewe = unique(simul_labels_we)\n",
    "\n",
    "\n",
    "    dictywd = {}\n",
    "    for unique in uniquewd:\n",
    "        dictywd[unique] = [i for i,j in enumerate(ywd) if j==unique]\n",
    "\n",
    "    dictywe = {}\n",
    "    for unique in uniquewe:\n",
    "        dictywe[unique] = [i for i,j in enumerate(ywe) if j==unique]\n",
    "\n",
    "    dictswd = {}\n",
    "    for unique in uniquewd:\n",
    "        dictswd[unique] = [i for i,j in enumerate(simul_labels_wd) if j==unique]\n",
    "\n",
    "    dictswe = {}\n",
    "    for unique in uniquewe:\n",
    "        dictswe[unique] = [i for i,j in enumerate(simul_labels_we) if j==unique]\n",
    "    \n",
    "    # Κανω δειγματοληψία απο τα generated για το σύνολο των WDs, WEs της εποχής, \n",
    "    #οπότε έχω δύο arrays με τόσα generated όσα οι WEs, WDs της εποχής αντίστοιχα\n",
    "\n",
    "    genwd = np.array(wd_np)\n",
    "    for cluster in uniquewd:\n",
    "        chosen = choose(len(dictswd[cluster]),xwd,dictywd[cluster])\n",
    "        for i,k in zip(dictswd[cluster],chosen):\n",
    "            genwd[i] = k.round(2)\n",
    "\n",
    "    genwe = np.array(we_np)\n",
    "    for cluster in uniquewe:\n",
    "        chosen = choose(len(dictswe[cluster]),xwe,dictywe[cluster])\n",
    "        for i,k in zip(dictswe[cluster],chosen):\n",
    "            genwe[i] = k.round(2)\n",
    "\n",
    "    sumwd = sumwe = 0\n",
    "    for month in months:\n",
    "        wdays, wends = workdayspermonth(month=month)\n",
    "        Months[month] = (genwd[sumwd:sumwd+wdays],genwe[sumwe:sumwe+wends])\n",
    "        sumwd += wdays\n",
    "        sumwe += wends\n",
    "        \n",
    "    return Months\n",
    "\n",
    "def generate_year_2_3(bus, period, power = 'real'):\n",
    "    year = pd.DataFrame()\n",
    "    for month in range(1,13):\n",
    "        t,s,res,real = decompose_bootstrap(bus.month(month=month, power=power), month=month, period=period)\n",
    "        weekdays, weekends = workdays(res)\n",
    "        resampled_wd = bootstrap_res(weekdays)\n",
    "        resampled_we = bootstrap_res(weekends)\n",
    "        resampled_month_res = concatinate(resampled_wd, resampled_we,month=month)\n",
    "\n",
    "        mhnas = dt.datetime.strptime(str(month), \"%m\").strftime(\"%B\")\n",
    "        #plt.figure(figsize=(20, 20))\n",
    "        #plt.tight_layout()\n",
    "\n",
    "        generated = t+s+resampled_month_res\n",
    "        generated.name ='Value'\n",
    "        gen = pd.DataFrame(generated)\n",
    "\n",
    "        real = pd.DataFrame(real)\n",
    "        year = year.append(gen)\n",
    "\n",
    "        plt.subplot(211)\n",
    "        plt.title(mhnas)\n",
    "        plt.plot(real['Value'], label='Real time series')\n",
    "        plt.plot(real['Value'])\n",
    "        plt.legend(loc='best')\n",
    "\n",
    "        plt.subplot(212)\n",
    "        plt.plot(gen['Value'], label='Generated time series')\n",
    "        plt.plot(gen['Value'])\n",
    "        plt.legend(loc='best')\n",
    "    \n",
    "    return year\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
